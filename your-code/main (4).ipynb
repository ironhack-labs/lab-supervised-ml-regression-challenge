{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Supervised ML Regression Competition</center></h1>\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"https://compraracciones.com/wp-content/uploads/2021/04/insurance.jpg\" style=\"height:200px\" style=\"width:100px\"/>\n",
    "\n",
    "<hr style=\"border:2px solid pink\"> </hr>\n",
    "\n",
    "You have been assigned the task of building a model that will predict the insurance cost\n",
    "\n",
    "You'll find the data in the csv file `insurance`\n",
    "\n",
    "\n",
    "- target col: \"charges\"\n",
    "\n",
    "\n",
    "<hr style=\"border:2px solid pink\"> </hr>\n",
    "\n",
    "\n",
    "**Guidelines:** \n",
    "\n",
    "\n",
    "- train_test_split\n",
    "    - random state = 42\n",
    "    - test size = 0.3\n",
    "\n",
    "\n",
    "- The one who gets the highest r2-score on test data wins\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "insurance = pd.read_csv(r\"C:\\Users\\igriz\\Documents\\BOOTCAMP 2024\\WEEK 5\\DAY1\\lab-supervised-ml-regression-challenge-main\\lab-supervised-ml-regression-challenge-main\\your-code\\insurance.csv\")\n",
    "insurance.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Data Exploration\n",
    "\n",
    "Let's start by loading our dataset and taking a first look at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance = pd.read_csv(r\"C:\\Users\\igriz\\Documents\\BOOTCAMP 2024\\WEEK 5\\DAY1\\lab-supervised-ml-regression-challenge-main\\lab-supervised-ml-regression-challenge-main\\your-code\\insurance.csv\")\n",
    "insurance.head(), insurance.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking for Missing Values\n",
    "\n",
    "It's important to know if our data has any missing values. Let's check that next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance.isnull().sum(), insurance.isna().sum()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Descriptive Statistics\n",
    "\n",
    "Now, let's move on to some descriptive statistics.\n",
    "\n",
    "Understanding the distribution of our data is crucial. Let's calculate some descriptive statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#insurance.describe(), \n",
    "#insurance.select_dtypes(include= 'object').columns\n",
    "#insurance.value_counts()\n",
    "categorical_cols = insurance.select_dtypes(include='object').columns\n",
    "for col in categorical_cols:\n",
    "    print(f\"\\nValue counts for {col}:\\n\", insurance[col].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis\n",
    "\n",
    "Visualizing the distributions of our features can provide valuable insights. Let's plot the distributions for 'age', 'bmi', and 'charges'.\n",
    "\n",
    "### Task:\n",
    "- Plot the histogram for 'age'\n",
    "- Plot the histogram for 'bmi'\n",
    "- Plot the histogram for 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.hist(insurance['age'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Age Distribution')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.hist(insurance['bmi'], bins=20, color='salmon', edgecolor='black')\n",
    "plt.title('BMI Distribution')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.hist(insurance['charges'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Charges Distribution')\n",
    "plt.xlabel('Charges')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relationship Between Variables\n",
    "\n",
    "Let's explore the relationship between some of our features and the target variable 'charges'. We'll create scatter plots to visualize these relationships.\n",
    "\n",
    "### Task:\n",
    "- Create a scatter plot for 'age' vs 'charges'\n",
    "- Create a scatter plot for 'bmi' vs 'charges'\n",
    "- Create a scatter plot for 'children' vs 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "plt.scatter(insurance['age'], insurance['charges'], color='skyblue')\n",
    "plt.title('Age vs Charges')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "plt.scatter(insurance['bmi'], insurance['charges'], color='salmon')\n",
    "plt.title('BMI vs Charges')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Add jitter to the 'children' column\n",
    "jittered_children = insurance['children'] + np.random.uniform(-0.2, 0.2, size=insurance.shape[0])\n",
    "\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "plt.scatter(jittered_children, insurance['charges'], color='lightgreen', alpha = .4)\n",
    "#plt.scatter(insurance['children'], insurance['charges'], color='lightgreen', alpha = .5)\n",
    "plt.title('Children vs Charges')\n",
    "plt.xlabel('Children')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Analysis\n",
    "\n",
    "Let's analyze the categorical features 'sex', 'smoker', and 'region' to see how they relate to 'charges'.\n",
    "\n",
    "### Task:\n",
    "- Plot the distribution of 'charges' for different 'sex'\n",
    "- Plot the distribution of 'charges' for different 'smoker'\n",
    "- Plot the distribution of 'charges' for different 'region'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(18, 5))\n",
    "\n",
    "plt.subplot(1, 3, 1)\n",
    "sns.boxplot(x='sex', y='charges', hue='sex', data=insurance, palette='pastel')\n",
    "plt.title('Charges by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.subplot(1, 3, 2)\n",
    "sns.boxplot(x='smoker', y='charges', hue='smoker', data=insurance, palette='Set2')\n",
    "plt.title('Charges by Smoker')\n",
    "plt.xlabel('Smoker')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.subplot(1, 3, 3)\n",
    "sns.boxplot(x='region', y='charges', hue='region', data=insurance, palette='Set3')\n",
    "plt.title('Charges by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Charges')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "To understand how our numerical features relate to each other and to the target variable, let's calculate and visualize the correlation matrix.\n",
    "\n",
    "### Taskz\n",
    "- Calculate the correlation matrix for the dataset\n",
    "- Visualize the correlation matrix using a heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# hot encoding\n",
    "insurance = pd.get_dummies(insurance, columns=['sex', 'smoker', 'region'], drop_first=True)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "correlationmtx = insurance.corr()\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlationmtx, annot=True, cmap='coolwarm', fmt='.2f', linewidths=0.5)\n",
    "plt.title(\"Correlation Matrix\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find the Naive Baseline\n",
    "\n",
    "Before we build any models, let's establish a naive baseline. This will help us understand how well our models perform compared to a simple approach. In regression problems, the naive baseline is often the mean of the target variable.\n",
    "\n",
    "### Task:\n",
    "- Calculate the mean of the target variable 'charges'\n",
    "- Explain why it's important to establish a naive baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insurance['charges'].mean()\n",
    "\n",
    "# This naive baseline is used to evaluate if the model performs better than a simple means calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Modelling Without GridSearch or Pipeline\n",
    "\n",
    "Let's build a simple linear regression model without any feature engineering, grid search, or pipeline. This will serve as our initial baseline for comparison.\n",
    "\n",
    "### Task:\n",
    "- Split the data into training and test sets\n",
    "- Train a simple linear regression model\n",
    "- Evaluate its performance using regression metrics\n",
    "- Write it down as a markdown below so you can keep track. This is a scientific experiment\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression as linereg\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "x = insurance.drop(['charges'], axis=1)\n",
    "y = insurance['charges']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .2, random_state=42)\n",
    "\n",
    "model = linereg()\n",
    "\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred= model.predict(xtest)\n",
    "\n",
    "mse = mean_squared_error(ytest, ypred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(ytest, ypred)\n",
    "print(f'R2-squared: {r2}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Now, let's brainstorm and create some new features to see if we can improve the model's performance.\n",
    "\n",
    "### Questions:\n",
    "1. Should we create an interaction feature between 'bmi' and 'children'? \n",
    "2. Should we create age groups to see if the model improves by categorizing age?\n",
    "3. Should we create a high-risk indicator based on 'smoker' and 'bmi'?\n",
    "\n",
    "- Remember nothing is set in stone, this is your experiment, your hypothesis. You may not need to, but its important to explore these questions\n",
    "\n",
    "### Task:\n",
    "- Create new features based on the questions above\n",
    "- Explain the rationale behind each feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interaction feature between BMI and children\n",
    "insurance['bmi_children_interaction'] = insurance['bmi'] * insurance['children']\n",
    "\n",
    "\n",
    "insurance['high_risk'] = ((insurance['smoker_yes'] == True) & (insurance['bmi'] > 30)).astype(int)\n",
    "\n",
    "# age groups\n",
    "bins = [18, 30, 40, 50, 60, 100]  # Define age bins\n",
    "labels = ['18-30', '31-40', '41-50', '51-60', '60+']  # Define labels for each age group\n",
    "\n",
    "insurance['age_group'] = pd.cut(insurance['age'], bins=bins, labels=labels, right=False)\n",
    "\n",
    "# hot encoding age group\n",
    "insurance = pd.get_dummies(insurance, columns=['age_group'], drop_first=True)\n",
    "\n",
    "\n",
    "# family size feature\n",
    "insurance['family_size'] = insurance['children'] + 1  # Add 1 for the policyholder\n",
    "\n",
    "# expenses per family member feature\n",
    "insurance['expenses_per_family_member'] = insurance['charges'] / insurance['family_size']\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an interaction feature between BMI and Children\n",
    "insurance['bmi_children_interaction'] = insurance['bmi'] * insurance['children']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling with Feature Engineering\n",
    "\n",
    "Now that we have new features, let's see if they improve our model's performance.\n",
    "Did it improve the performance? Yes? No? Why\n",
    "\n",
    "### Task:\n",
    "- Split the data into training and test sets\n",
    "- Train a linear regression model with the new features\n",
    "- Evaluate its performance using regression metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing the updated model\n",
    "x = insurance.drop(['charges'], axis=1)\n",
    "y = insurance['charges']\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = .2, random_state=42)\n",
    "\n",
    "model = linereg()\n",
    "\n",
    "model.fit(xtrain, ytrain)\n",
    "\n",
    "ypred= model.predict(xtest)\n",
    "\n",
    "mse = mean_squared_error(ytest, ypred)\n",
    "\n",
    "print(f'Mean Squared Error: {mse}')\n",
    "\n",
    "r2 = r2_score(ytest, ypred)\n",
    "print(f'R2-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling with Pipeline and Grid Search\n",
    "\n",
    "Now, let's see how using pipelines can simplify our workflow and prevent data leakage. We'll also use GridSearchCV to find the best hyperparameters.\n",
    "\n",
    "### Task:\n",
    "- Create a pipeline that includes scaling and linear regression\n",
    "- Define a parameter grid for hyperparameter tuning\n",
    "- Use GridSearchCV to find the best parameters and evaluate the model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# parameter grid\n",
    "paragrid = {\n",
    "    'regressor__alpha': [.01, .1, 1, 10, 100]\n",
    "}\n",
    "\n",
    "# scaling and ridge regression pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', Ridge())\n",
    "])\n",
    "\n",
    "# grid search\n",
    "grids = GridSearchCV(\n",
    "    estimator = pipeline,\n",
    "    param_grid = paragrid,\n",
    "    scoring = 'neg_mean_squared_error',\n",
    "    cv = 5, # 5 fold cross validation\n",
    "    n_jobs = -1\n",
    ")\n",
    "\n",
    "grids.fit(xtrain, ytrain)\n",
    "\n",
    "bestpipe = grids.best_estimator_\n",
    "\n",
    "ypred = bestpipe.predict(xtest)\n",
    "\n",
    "\n",
    "mse = mean_squared_error(ytest, ypred)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "r2 = r2_score(ytest, ypred)\n",
    "print(f'R2-squared: {r2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trying Another Model with Pipeline\n",
    "\n",
    "Let's try using a Gradient Boosting Regressor to see if it performs better.\n",
    "\n",
    "### Task:\n",
    "- Create and use a pipeline for Gradient Boosting Regressor\n",
    "- Define a parameter grid for grid search\n",
    "- Use GridSearchCV to find the best parameters and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "paragrid = {\n",
    "    'regressor__n_estimators': [100, 200],       # Number of boosting stages\n",
    "    'regressor__learning_rate': [0.05, 0.1, 0.2], # Learning rate\n",
    "    'regressor__max_depth': [3, 4, 5]           # Maximum depth of the individual estimators\n",
    "}\n",
    "\n",
    "# pipeline with scaling and GBR\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('regressor', GradientBoostingRegressor(random_state=42))  \n",
    "])\n",
    "\n",
    "# Use GridSearchCV to search for the best hyperparameters\n",
    "grids = GridSearchCV(\n",
    "    estimator=pipeline,\n",
    "    param_grid=paragrid,\n",
    "    scoring='neg_mean_squared_error',  # Optimize for negative MSE\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "grids.fit(xtrain, ytrain)\n",
    "\n",
    "bestpipeline = grids.best_estimator_\n",
    "\n",
    "ypred = bestpipeline.predict(xtest)\n",
    "\n",
    "mse = mean_squared_error(ytest, ypred)\n",
    "r2 = r2_score(ytest, ypred)\n",
    "\n",
    "print(f\"Best Parameters: {grids.best_params_}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse}\")\n",
    "print(f\"R2 Score: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. GridSearch with Several Models\n",
    "\n",
    "Finally, let's compare several models using GridSearchCV to find the best one.\n",
    "\n",
    "### Task:\n",
    "- Define multiple models and their parameter grids\n",
    "- Use GridSearchCV to find the best model and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "models_param_grids = {\n",
    "    'Ridge': {\n",
    "        'model': Ridge(),\n",
    "        'params': {'regressor__alpha': [0.1, 1, 10, 100]}\n",
    "    },\n",
    "    'RandomForest': {\n",
    "        'model': RandomForestRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__max_depth': [None, 10, 20],\n",
    "            'regressor__min_samples_split': [2, 5, 10]\n",
    "        }\n",
    "    },\n",
    "    'GradientBoosting': {\n",
    "        'model': GradientBoostingRegressor(random_state=42),\n",
    "        'params': {\n",
    "            'regressor__n_estimators': [100, 200],\n",
    "            'regressor__learning_rate': [0.05, 0.1, 0.2],\n",
    "            'regressor__max_depth': [3, 4, 5]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# calculate underestimation and overestimation errors\n",
    "def calculate_errors(ytest, ypred):\n",
    "    underestimation_error = np.sum(ytest[ytest > ypred] - ypred[ytest > ypred])\n",
    "    overestimation_error = np.sum(ypred[ytest < ypred] - ytest[ytest < ypred])\n",
    "    return underestimation_error, overestimation_error\n",
    "\n",
    "# ridge regression\n",
    "pipeline_ridge = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('regressor', models_param_grids['Ridge']['model'])\n",
    "])\n",
    "grid_search_ridge = GridSearchCV(\n",
    "    estimator=pipeline_ridge,\n",
    "    param_grid=models_param_grids['Ridge']['params'],\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_ridge.fit(xtrain, ytrain)\n",
    "y_pred_ridge = grid_search_ridge.predict(xtest)\n",
    "\n",
    "# evaluate ridge\n",
    "rmse = np.sqrt(mean_squared_error(ytest, y_pred_ridge))\n",
    "mse_ridge = mean_squared_error(ytest, y_pred_ridge)\n",
    "r2_ridge = r2_score(ytest, y_pred_ridge)\n",
    "\n",
    "# underestimation and overestimation errors\n",
    "underestimation_error_ridge, overestimation_error_ridge = calculate_errors(ytest, y_pred_ridge)\n",
    "\n",
    "# total potential cost/loss\n",
    "total_potential_loss_ridge = underestimation_error_ridge + overestimation_error_ridge\n",
    "\n",
    "results.append({\n",
    "    'Model': 'Ridge', \n",
    "    'Best Params': grid_search_ridge.best_params_, \n",
    "    'MSE': mse_ridge, \n",
    "    'RMSE': rmse, \n",
    "    'R²': r2_ridge, \n",
    "    'Underestimation Error': underestimation_error_ridge,\n",
    "    'Overestimation Error': overestimation_error_ridge,\n",
    "    'Total Potential Cost/Loss': total_potential_loss_ridge\n",
    "})\n",
    "\n",
    "# random forest regression\n",
    "pipeline_rf = Pipeline([\n",
    "    ('regressor', models_param_grids['RandomForest']['model'])\n",
    "])\n",
    "grid_search_rf = GridSearchCV(\n",
    "    estimator=pipeline_rf,\n",
    "    param_grid=models_param_grids['RandomForest']['params'],\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_rf.fit(xtrain, ytrain)\n",
    "y_pred_rf = grid_search_rf.predict(xtest)\n",
    "\n",
    "# evaluate random forest\n",
    "rmse = np.sqrt(mean_squared_error(ytest, y_pred_rf))\n",
    "mse_rf = mean_squared_error(ytest, y_pred_rf)\n",
    "r2_rf = r2_score(ytest, y_pred_rf)\n",
    "\n",
    "# underestimation and overestimation errors\n",
    "underestimation_error_rf, overestimation_error_rf = calculate_errors(ytest, y_pred_rf)\n",
    "\n",
    "# total potential cost/loss\n",
    "total_potential_loss_rf = underestimation_error_rf + overestimation_error_rf\n",
    "\n",
    "results.append({\n",
    "    'Model': 'RandomForest', \n",
    "    'Best Params': grid_search_rf.best_params_, \n",
    "    'MSE': mse_rf, \n",
    "    'RMSE': rmse, \n",
    "    'R²': r2_rf, \n",
    "    'Underestimation Error': underestimation_error_rf,\n",
    "    'Overestimation Error': overestimation_error_rf,\n",
    "    'Total Potential Cost/Loss': total_potential_loss_rf\n",
    "})\n",
    "\n",
    "# Gradient Boosting Regression\n",
    "pipeline_gb = Pipeline([\n",
    "    ('regressor', models_param_grids['GradientBoosting']['model'])\n",
    "])\n",
    "grid_search_gb = GridSearchCV(\n",
    "    estimator=pipeline_gb,\n",
    "    param_grid=models_param_grids['GradientBoosting']['params'],\n",
    "    scoring='neg_mean_squared_error',\n",
    "    cv=5,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_gb.fit(xtrain, ytrain)\n",
    "y_pred_gb = grid_search_gb.predict(xtest)\n",
    "\n",
    "# evaluate gradient boosting\n",
    "rmse = np.sqrt(mean_squared_error(ytest, y_pred_gb))\n",
    "mse_gb = mean_squared_error(ytest, y_pred_gb)\n",
    "r2_gb = r2_score(ytest, y_pred_gb)\n",
    "\n",
    "# underestimation and overestimation errors\n",
    "underestimation_error_gb, overestimation_error_gb = calculate_errors(ytest, y_pred_gb)\n",
    "\n",
    "# total potential cost/loss\n",
    "total_potential_loss_gb = underestimation_error_gb + overestimation_error_gb\n",
    "\n",
    "results.append({\n",
    "    'Model': 'GradientBoosting', \n",
    "    'Best Params': grid_search_gb.best_params_, \n",
    "    'MSE': mse_gb, \n",
    "    'RMSE': rmse, \n",
    "    'R²': r2_gb, \n",
    "    'Underestimation Error': underestimation_error_gb,\n",
    "    'Overestimation Error': overestimation_error_gb,\n",
    "    'Total Potential Cost/Loss': total_potential_loss_gb\n",
    "})\n",
    "\n",
    "\n",
    "for result in results:\n",
    "    print(f\"Model: {result['Model']}\")\n",
    "    print(f\"Best Parameters: {result['Best Params']}\")\n",
    "    print(f\"Mean Squared Error (MSE): {result['MSE']}\")\n",
    "    print(f\"RMSE: {result['RMSE']}\")\n",
    "    print(f\"R² Score: {result['R²']}\")\n",
    "    print(f\"Underestimation Error: {result['Underestimation Error']}\")\n",
    "    print(f\"Overestimation Error: {result['Overestimation Error']}\")\n",
    "    print(f\"Total Potential Cost/Loss: {result['Total Potential Cost/Loss']}\")\n",
    "    print(\"-\" * 30)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Master Challenge\n",
    "\n",
    "## 8. Calculating Potential Cost or Loss\n",
    "\n",
    "### Challenge:\n",
    "Now that you've built and optimized your models, it's time for the final challenge! Your task is to minimize the Root Mean Squared Error (RMSE) of your model's predictions and calculate the potential financial impact of your model's errors.\n",
    "\n",
    "### Task:\n",
    "1. Calculate the RMSE of your final model's predictions.\n",
    "2. Break down the errors into underestimation and overestimation.\n",
    "3. Calculate the total potential cost or loss to the company.\n",
    "4. Compete with your classmates to see who can achieve the lowest RMSE and financial impact!\n",
    "\n",
    "### Explanation:\n",
    "The RMSE provides an estimate of the average error in your model's predictions. We will also analyze the errors by categorizing them into underestimations and overestimations to understand their financial impact.\n",
    "\n",
    "#### Steps to Calculate Underestimation and Overestimation Errors:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - Use the `mean_squared_error` function from `sklearn.metrics` and pass your actual values (`y_test`) and predicted values (`y_pred_final`) to it.\n",
    "   - Take the square root of the result to get the RMSE.\n",
    "   \n",
    "2. **Calculate Underestimation Error**:\n",
    "   - Identify the instances where the actual charges (`y_test`) are greater than the predicted charges (`y_pred_final`).\n",
    "   - For these instances, calculate the difference between the actual and predicted charges.\n",
    "   - Sum these differences to get the total underestimation error.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - Identify the instances where the actual charges (`y_test`) are less than the predicted charges (`y_pred_final`).\n",
    "   - For these instances, calculate the difference between the predicted and actual charges.\n",
    "   - Sum these differences to get the total overestimation error.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - Add the total underestimation error and the total overestimation error to get the total potential cost or loss.\n",
    "\n",
    "### Let's see who can build the best model!\n",
    "\n",
    "#### Detailed Instructions:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - Use `mean_squared_error` with `y_test` and `y_pred_final`.\n",
    "   - Use `np.sqrt` to take the square root of the result.\n",
    "\n",
    "2. **Calculate Underestimation Error**:\n",
    "   - Use a boolean condition to filter `y_test` values that are greater than `y_pred_final`.\n",
    "   - Subtract the predicted values from the actual values for these instances.\n",
    "   - Sum these differences.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - Use a boolean condition to filter `y_test` values that are less than `y_pred_final`.\n",
    "   - Subtract the actual values from the predicted values for these instances.\n",
    "   - Sum these differences.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - Add the results of the underestimation error and overestimation error to get the total potential cost or loss.\n",
    "\n",
    "### Example Walkthrough:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - `rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))`\n",
    "   - This gives you the average prediction error in dollars.\n",
    "\n",
    "2. **Calculate Underestimation Error**:\n",
    "   - `underestimation_error = np.sum(y_test[y_test > y_pred_final] - y_pred_final[y_test > y_pred_final])`\n",
    "   - This gives you the total amount by which the model undercharged.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - `overestimation_error = np.sum(y_pred_final[y_test < y_pred_final] - y_test[y_test < y_pred_final])`\n",
    "   - This gives you the total amount by which the model overcharged.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - `total_potential_loss = underestimation_error + overestimation_error`\n",
    "   - This gives you the total financial impact of the model's errors.\n",
    "\n",
    "### Leaderboard:\n",
    "Post your RMSE score and total potential cost or loss on the class leaderboard. The student with the lowest RMSE and total potential cost or loss wins bragging rights\n",
    "\n",
    "### Post Your Results \n",
    "\n",
    "- Name\n",
    "- Model Type\n",
    "- RMSE\n",
    "- Underestimation Error\n",
    "- Overestimation Error\n",
    "- Total Potential Cost/Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Diego Rosa\n",
    "\n",
    "Model: RandomForest\n",
    "RMSE: 1353.795623214729\n",
    "Underestimation Error: 76069.5659998999\n",
    "Overestimation Error: 56915.35298535049\n",
    "Total Potential Cost/Loss: 132984.9189852504"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed the lab. Here's a summary of what we've covered:\n",
    "1. Established a naive baseline using the mean of the target variable.\n",
    "2. Built an initial linear regression model without any feature engineering or optimization.\n",
    "3. Performed feature engineering to create new, potentially useful features.\n",
    "4. Used pipelines and GridSearchCV to optimize the model.\n",
    "5. Evaluated the final model's performance using RMSE to understand its business impact.\n",
    "\n",
    "By following these steps, you now have a robust understanding of how to approach a regression problem, from initial exploration to model optimization and business impact assessment. Great job!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae536f6b95df49dd083f07529981141025184c1d22e3e1982b15f49841b31737"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
