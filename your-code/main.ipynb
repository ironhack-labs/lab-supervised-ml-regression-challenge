{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><center>Supervised ML Regression Competition</center></h1>\n",
    "\n",
    "\n",
    "<img align=\"center\" src=\"https://compraracciones.com/wp-content/uploads/2021/04/insurance.jpg\" style=\"height:200px\" style=\"width:100px\"/>\n",
    "\n",
    "<hr style=\"border:2px solid pink\"> </hr>\n",
    "\n",
    "You have been assigned the task of building a model that will predict the insurance cost\n",
    "\n",
    "You'll find the data in the csv file `insurance`\n",
    "\n",
    "\n",
    "- target col: \"charges\"\n",
    "\n",
    "\n",
    "<hr style=\"border:2px solid pink\"> </hr>\n",
    "\n",
    "\n",
    "**Guidelines:** \n",
    "\n",
    "\n",
    "- train_test_split\n",
    "    - random state = 42\n",
    "    - test size = 0.3\n",
    "\n",
    "\n",
    "- The one who gets the highest r2-score on test data wins\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Initial Data Exploration\n",
    "\n",
    "Let's start by loading our dataset and taking a first look at it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loads the insurance dataset and provides basic information about it.\n",
    "# Loads the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Reads the data file\n",
    "data = pd.read_csv('insurance.csv', header=0)\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Provides dataset information\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sets the first row as column headers\n",
    "#data.columns = data.iloc[0]\n",
    "#data = data[1:]\n",
    "\n",
    "# Prints the data types present in the data\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures 'age' and 'children' columns are integers\n",
    "data.loc[:, 'age'] = pd.to_numeric(data['age'], errors='coerce').fillna(0).astype(int)\n",
    "data.loc[:, 'children'] = pd.to_numeric(data['children'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Ensures 'bmi' and 'charges' columns are floats\n",
    "data.loc[:, 'bmi'] = pd.to_numeric(data['bmi'], errors='coerce').fillna(data['bmi'].mean()).astype(float)\n",
    "data.loc[:, 'charges'] = pd.to_numeric(data['charges'], errors='coerce').fillna(data['charges'].mean()).astype(float)\n",
    "\n",
    "# Prints data types to verify\n",
    "print(data.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Checking for Missing Values\n",
    "\n",
    "It's important to know if our data has any missing values. Let's check that next.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checks the dataset for missing values\n",
    "print(data.isnull().sum())\n",
    "\n",
    "# The dataset has no missing data. Because of this no further analysis of the missing values will be conducted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 3. Descriptive Statistics\n",
    "\n",
    "Now, let's move on to some descriptive statistics.\n",
    "\n",
    "Understanding the distribution of our data is crucial. Let's calculate some descriptive statistics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows descriptive statistics for the entire dataset\n",
    "print(\"Descriptive Statistics for the Dataset:\")\n",
    "print(data.describe(include='all'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Distribution Analysis\n",
    "\n",
    "Visualizing the distributions of our features can provide valuable insights. Let's plot the distributions for 'age', 'bmi', and 'charges'.\n",
    "\n",
    "### Task:\n",
    "- Plot the histogram for 'age'\n",
    "- Plot the histogram for 'bmi'\n",
    "- Plot the histogram for 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plots the histogram for 'age'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(data['age'], bins=20, color='skyblue', edgecolor='black')\n",
    "plt.title('Histogram of Age')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plots the histogram for 'bmi'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(data['bmi'], bins=20, color='lightgreen', edgecolor='black')\n",
    "plt.title('Histogram of BMI')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plots the histogram for 'charges'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.hist(data['charges'], bins=20, color='salmon', edgecolor='black')\n",
    "plt.title('Histogram of Charges')\n",
    "plt.xlabel('Charges')\n",
    "plt.ylabel('Frequency')\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Relationship Between Variables\n",
    "\n",
    "Let's explore the relationship between some of our features and the target variable 'charges'. We'll create scatter plots to visualize these relationships.\n",
    "\n",
    "### Task:\n",
    "- Create a scatter plot for 'age' vs 'charges'\n",
    "- Create a scatter plot for 'bmi' vs 'charges'\n",
    "- Create a scatter plot for 'children' vs 'charges'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Creates a scatter plot for 'age' vs 'charges'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(data['age'], data['charges'], alpha=0.7, color='blue', edgecolor='black')\n",
    "plt.title('Scatter Plot: Age vs Charges')\n",
    "plt.xlabel('Age')\n",
    "plt.ylabel('Charges')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Creates a scatter plot for 'bmi' vs 'charges'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(data['bmi'], data['charges'], alpha=0.7, color='green', edgecolor='black')\n",
    "plt.title('Scatter Plot: BMI vs Charges')\n",
    "plt.xlabel('BMI')\n",
    "plt.ylabel('Charges')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Creates a scatter plot for 'children' vs 'charges'\n",
    "plt.figure(figsize=(8, 5))\n",
    "plt.scatter(data['children'], data['charges'], alpha=0.7, color='red', edgecolor='black')\n",
    "plt.title('Scatter Plot: Children vs Charges')\n",
    "plt.xlabel('Number of Children')\n",
    "plt.ylabel('Charges')\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Categorical Analysis\n",
    "\n",
    "Let's analyze the categorical features 'sex', 'smoker', and 'region' to see how they relate to 'charges'.\n",
    "\n",
    "### Task:\n",
    "- Plot the distribution of 'charges' for different 'sex'\n",
    "- Plot the distribution of 'charges' for different 'smoker'\n",
    "- Plot the distribution of 'charges' for different 'region'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plots the distribution of 'charges' for different 'sex'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='sex', y='charges', data=data, hue='sex', dodge=False)\n",
    "plt.title('Distribution of Charges by Sex')\n",
    "plt.xlabel('Sex')\n",
    "plt.ylabel('Charges')\n",
    "plt.legend([], [], frameon=False)  # Disable redundant legend\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plots the distribution of 'charges' for different 'smoker'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='smoker', y='charges', data=data, hue='smoker', dodge=False)\n",
    "plt.title('Distribution of Charges by Smoker')\n",
    "plt.xlabel('Smoker')\n",
    "plt.ylabel('Charges')\n",
    "plt.legend([], [], frameon=False)  # Disable redundant legend\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()\n",
    "\n",
    "# Plots the distribution of 'charges' for different 'region'\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='region', y='charges', data=data, hue='region', dodge=False)\n",
    "plt.title('Distribution of Charges by Region')\n",
    "plt.xlabel('Region')\n",
    "plt.ylabel('Charges')\n",
    "plt.legend([], [], frameon=False)  # Disable redundant legend\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Correlation Analysis\n",
    "\n",
    "To understand how our numerical features relate to each other and to the target variable, let's calculate and visualize the correlation matrix.\n",
    "\n",
    "### Task:\n",
    "- Calculate the correlation matrix for the dataset\n",
    "- Visualize the correlation matrix using a heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports the necessary libraries\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# One-hot encoding\n",
    "data_encoded = pd.get_dummies(data, drop_first = True)\n",
    "\n",
    "# Calculates the correlation matrix\n",
    "correlation_matrix = data_encoded.corr()\n",
    "\n",
    "# Visualizes the correlation matrix using a heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, fmt='.2f', cmap='coolwarm', cbar=True, square=True, linewidths=0.5)\n",
    "plt.title('Correlation Matrix Heatmap', fontsize=16)\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.yticks(rotation=0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling time!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Find the Naive Baseline\n",
    "\n",
    "Before we build any models, let's establish a naive baseline. This will help us understand how well our models perform compared to a simple approach. In regression problems, the naive baseline is often the mean of the target variable.\n",
    "\n",
    "### Task:\n",
    "- Calculate the mean of the target variable 'charges'\n",
    "- Explain why it's important to establish a naive baseline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculates the mean of the target variable 'charges'\n",
    "mean_charges = data['charges'].mean()\n",
    "\n",
    "# Prints the mean value\n",
    "print(f\"The mean of the target variable 'charges' is: {mean_charges:.2f}\")\n",
    "\n",
    "# It's important to establish a naive baseline because it provides a minimum performance\n",
    "# standard for my model. If my model can't beat this baseline, it is ineffective."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Modelling Without GridSearch or Pipeline\n",
    "\n",
    "Let's build a simple linear regression model without any feature engineering, grid search, or pipeline. This will serve as our initial baseline for comparison.\n",
    "\n",
    "### Task:\n",
    "- Split the data into training and test sets\n",
    "- Train a simple linear regression model\n",
    "- Evaluate its performance using regression metrics\n",
    "- Write it down as a markdown below so you can keep track. This is a scientific experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data into training and test sets, trains a simple linear regression model,\n",
    "# Evaluates its performance using regression metrics.\n",
    "\n",
    "# Imports the necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Assuming data_encoded is preprocessed and includes the target variable 'charges'\n",
    "\n",
    "# Splits the features and the target\n",
    "X = data_encoded.drop(columns=['charges'])  # Replace 'charges' with your actual target column\n",
    "y = data_encoded['charges']\n",
    "\n",
    "# Splits the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializes the Linear Regression model\n",
    "linear_model = LinearRegression()\n",
    "\n",
    "# Trains the model on the training data\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicts on the test set\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluates the model's performance\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Prints the metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "**Results**\n",
    "\n",
    "**Mean Absolute Error (MAE):** 4901.38\n",
    "                              \n",
    "**Mean Squared Error (MSE):** 42549664.96\n",
    "                             \n",
    "**R-squared (R²):** 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps:\n",
    "\t1.\tSplit the Data:\n",
    "\t•\tDivide the dataset into training and testing sets using train_test_split.\n",
    "\t2.\tTrain a Simple Linear Regression Model:\n",
    "\t•\tUse the LinearRegression class from sklearn to fit the training data.\n",
    "\t3.\tEvaluate the Model:\n",
    "\t•\tUse regression metrics such as:\n",
    "\t•\tMean Absolute Error (MAE)\n",
    "\t•\tMean Squared Error (MSE)\n",
    "\t•\tR-squared (R²)\n",
    "\n",
    "Resulting mean absolute error(MAE): 4901.38\n",
    "Resulting mean squared error (MSE): 42549664.96\n",
    "R-squared (R²): 0.74"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Feature Engineering\n",
    "\n",
    "Now, let's brainstorm and create some new features to see if we can improve the model's performance.\n",
    "\n",
    "### Questions:\n",
    "1. Should we create an interaction feature between 'bmi' and 'children'? \n",
    "2. Should we create age groups to see if the model improves by categorizing age?\n",
    "3. Should we create a high-risk indicator based on 'smoker' and 'bmi'?\n",
    "\n",
    "- Remember nothing is set in stone, this is your experiment, your hypothesis. You may not need to, but its important to explore these questions\n",
    "\n",
    "### Task:\n",
    "- Create new features based on the questions above\n",
    "- Explain the rationale behind each feature\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Create a copy of the dataset to add new features\n",
    "data_encoded = data_encoded.copy()\n",
    "\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure the 'smoker' column is encoded into numeric values\n",
    "if 'smoker' in data_encoded.columns and data_encoded['smoker_yes'].dtype == 'object':\n",
    "    data_encoded['smoker_yes'] = data_encoded['smoker_yes'].apply(lambda x: 1 if x.lower() == 'yes' else 0)\n",
    "\n",
    "# 1. Interaction feature between 'bmi' and 'children'\n",
    "data_encoded['bmi_children_interaction'] = data_encoded['bmi'] * data_encoded['children']\n",
    "\n",
    "# 2. Categorize 'age' into age groups\n",
    "age_bins = [0, 18, 30, 45, 60, 100]  # Example age bins\n",
    "age_labels = ['0-18', '19-30', '31-45', '46-60', '61+']\n",
    "data_encoded['age_group'] = pd.cut(data_encoded['age'], bins=age_bins, labels=age_labels)\n",
    "\n",
    "# 3. High-risk indicator based on 'smoker' and 'bmi'\n",
    "high_bmi_threshold = 30  # Example threshold for high BMI\n",
    "data_encoded['high_risk'] = np.where(\n",
    "    (data_encoded['smoker_yes'] == 1) & (data_encoded['bmi'] > high_bmi_threshold), 1, 0\n",
    ")\n",
    "\n",
    "# Display the first few rows of the modified dataset to verify new features\n",
    "data_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Modelling with Feature Engineering\n",
    "\n",
    "Now that we have new features, let's see if they improve our model's performance.\n",
    "Did it improve the performance? Yes? No? Why\n",
    "\n",
    "### Task:\n",
    "- Split the data into training and test sets\n",
    "- Train a linear regression model with the new features\n",
    "- Evaluate its performance using regression metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splits the data with the new features into training and test sets. Trains a linear regression model with the\n",
    "# new features. Evaluates the performance of this model using regression metrics.\n",
    "\n",
    "# Imports the necessary libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features and target variable\n",
    "X = data_encoded.drop(columns=['charges'])  # Drops the target column\n",
    "y = data_encoded['charges']  # Target variable\n",
    "\n",
    "# Uses one-hot encoding for age_group\n",
    "X = pd.get_dummies(X, drop_first = True)\n",
    "\n",
    "print(X.dtypes)\n",
    "\n",
    "# Splits the data into training and test sets (80%-20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Trains a linear regression model\n",
    "linear_model = LinearRegression()\n",
    "linear_model.fit(X_train, y_train)\n",
    "\n",
    "# Makes predictions on the test data\n",
    "y_pred = linear_model.predict(X_test)\n",
    "\n",
    "# Evaluates the model's performance using regression metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Prints the evaluation metrics\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "**Mean Absolute Error (MAE):** 3680.32\n",
    "\n",
    "**Mean Squared Error (MSE):** 26999974.38\n",
    "\n",
    "**R-squared (R²):** 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new features improved our model. The **revised** model is better than the baseline. \n",
    "It has lower MAE and MSE scores, which indicate higher prediction accuracy, and the R2 increased\n",
    "from 0.74 to 0.84, which means that it explains more of the variance in the target variable (charges).\n",
    "\n",
    "The results are as follow:\n",
    "**Baseline Model**\t\n",
    "\n",
    "**MAE**\t4901.38\n",
    "\n",
    "**MSE**\t42,549,664.96\t\n",
    "\n",
    "**R²**\t0.74\n",
    "\n",
    "**Revised Model**\n",
    "\n",
    "**MAE**\t3680.32\n",
    "\n",
    "**MSE** 26,999,974.38\n",
    "\n",
    "**R²** 0.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Modelling with Pipeline and Grid Search\n",
    "\n",
    "Now, let's see how using pipelines can simplify our workflow and prevent data leakage. We'll also use GridSearchCV to find the best hyperparameters.\n",
    "\n",
    "### Task:\n",
    "- Create a pipeline that includes scaling and linear regression\n",
    "- Define a parameter grid for hyperparameter tuning\n",
    "- Use GridSearchCV to find the best parameters and evaluate the model performance\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_encoded = X_encoded.apply(pd.to_numeric, errors = 'coerce')\n",
    "X_encoded = X_encoded.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates a pipeline that includes scaling and linear regression, defines a parameter grid for hyperparameter tuning,\n",
    "# and uses GridSearchCV to find the best parameters and evaluate the model performance\n",
    "\n",
    "# Imports the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Encodes categorical columns using one-hot encoding (in case any still remain)\n",
    "# Assumes 'age_group' is the only categorical column\n",
    "X_encoded = pd.get_dummies(data_encoded.drop(columns=['charges']), drop_first=True)  # Drop 'charges' and encode\n",
    "y = data_encoded['charges']  # Target variable\n",
    "\n",
    "# Splits the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creates a pipeline with scaling and linear regression\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('regressor', LinearRegression())  # Regression step\n",
    "])\n",
    "\n",
    "# Defines a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'regressor__fit_intercept': [True, False]  # Whether to calculate the intercept\n",
    "}\n",
    "\n",
    "# Uses GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluates the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculates performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Displays the best parameters and evaluation metrics\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results:**\n",
    "\n",
    "Fitting 5 folds for each of 2 candidates, totalling **10 fits**\n",
    "\n",
    "**Best Parameters:** {'regressor__fit_intercept': True}\n",
    "\n",
    "**Mean Absolute Error (MAE):** 3680.32\n",
    "\n",
    "**Mean Squared Error (MSE):** 26999974.38\n",
    "\n",
    "**R-squared (R²):** 0.84\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Trying Another Model with Pipeline\n",
    "\n",
    "Let's try using a Gradient Boosting Regressor to see if it performs better.\n",
    "\n",
    "### Task:\n",
    "- Create and use a pipeline for Gradient Boosting Regressor\n",
    "- Define a parameter grid for grid search\n",
    "- Use GridSearchCV to find the best parameters and evaluate the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creates and uses a pipeline for Gradient Boosting Regressor, defines a parameter grid for grid search,\n",
    "# Uses GridSearchCV to find the best parameters and evaluates the model\n",
    "\n",
    "# Imports the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Encodes categorical columns using one-hot encoding\n",
    "X_encoded = pd.get_dummies(data_encoded.drop(columns=['charges']), drop_first=True)\n",
    "y = data_encoded['charges']\n",
    "\n",
    "# Splits the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Creates a pipeline for Gradient Boosting Regressor\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('gbr', GradientBoostingRegressor(random_state=42))  # Gradient Boosting step\n",
    "])\n",
    "\n",
    "# Defines a parameter grid for hyperparameter tuning\n",
    "param_grid = {\n",
    "    'gbr__n_estimators': [100, 200, 300],  # Number of trees\n",
    "    'gbr__learning_rate': [0.01, 0.1, 0.2],  # Learning rate\n",
    "    'gbr__max_depth': [3, 5, 7]  # Maximum depth of trees\n",
    "}\n",
    "\n",
    "# Uses GridSearchCV to find the best parameters\n",
    "grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', verbose=1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Evaluates the best model on the test set\n",
    "best_model = grid_search.best_estimator_\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calculates performance metrics\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Displays the best parameters and evaluation metrics\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Mean Absolute Error (MAE): {mae:.2f}\")\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R²): {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "\n",
    "Fitting 5 folds for each of 27 candidates, totalling **135 fits**\n",
    "\n",
    "**Best Parameters:** {'gbr__learning_rate': 0.1, 'gbr__max_depth': 3, 'gbr__n_estimators': 100}\n",
    "\n",
    "**Mean Absolute Error (MAE):** 2360.01\n",
    "\n",
    "**Mean Squared Error (MSE):** 17472493.13\n",
    "\n",
    "**R-squared (R²):** 0.89"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. GridSearch with Several Models\n",
    "\n",
    "Finally, let's compare several models using GridSearchCV to find the best one.\n",
    "\n",
    "### Task:\n",
    "- Define multiple models and their parameter grids\n",
    "- Use GridSearchCV to find the best model and parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defines multiple models and their parameter grids\n",
    "# Uses GridSearchCV to find the best model and parameters.\n",
    "\n",
    "# Imports the necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression, ElasticNet\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Encodes categorical columns using one-hot encoding\n",
    "X_encoded = pd.get_dummies(data_encoded.drop(columns=['charges']), drop_first=True)\n",
    "y = data_encoded['charges']\n",
    "\n",
    "# Splits the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Defines multiple models and their parameter grids\n",
    "models_and_parameters = [\n",
    "    # Linear Regression\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', LinearRegression())\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__fit_intercept': [True, False]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Gradient Boosting Regressor\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', GradientBoostingRegressor(random_state=42))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'model__max_depth': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Random Forest Regressor\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', RandomForestRegressor(random_state=42))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__max_depth': [5, 10, 15]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # Support Vector Regressor (SVR)\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', SVR())\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__epsilon': [0.01, 0.1, 1]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # ElasticNet\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', ElasticNet(random_state=42))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__alpha': [0.01, 0.1, 1],\n",
    "            'model__l1_ratio': [0.2, 0.5, 0.8]\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # K-Nearest Neighbors Regressor (KNN)\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', KNeighborsRegressor())\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__n_neighbors': [3, 5, 7],\n",
    "            'model__weights': ['uniform', 'distance']\n",
    "        }\n",
    "    },\n",
    "    \n",
    "    # XGBoost Regressor\n",
    "    {\n",
    "        'pipeline': Pipeline([\n",
    "            ('scaler', StandardScaler()),\n",
    "            ('model', XGBRegressor(random_state=42, eval_metric='rmse'))\n",
    "        ]),\n",
    "        'param_grid': {\n",
    "            'model__n_estimators': [100, 200, 300],\n",
    "            'model__learning_rate': [0.01, 0.1, 0.2],\n",
    "            'model__max_depth': [3, 5, 7]\n",
    "        }\n",
    "    }\n",
    "]  \n",
    "\n",
    "# Iterates through the models and evaluate using GridSearchCV\n",
    "best_model = None\n",
    "best_score = -float('inf')\n",
    "best_params = None\n",
    "\n",
    "for item in models_and_parameters:\n",
    "    pipeline = item['pipeline']\n",
    "    param_grid = item['param_grid']\n",
    "    \n",
    "    grid_search = GridSearchCV(pipeline, param_grid, cv=5, scoring='r2', verbose=1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Check if the current model performs better\n",
    "    if grid_search.best_score_ > best_score:\n",
    "        best_model = grid_search.best_estimator_\n",
    "        best_score = grid_search.best_score_\n",
    "        best_params = grid_search.best_params_\n",
    "\n",
    "# Evaluates the best model on the test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "# Displays the results\n",
    "print(\"Best Model:\", type(best_model['model']).__name__)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "print(f\"Cross-Validation R²: {best_score:.2f}\")\n",
    "print(f\"Test Set MAE: {mae:.2f}\")\n",
    "print(f\"Test Set MSE: {mse:.2f}\")\n",
    "print(f\"Test Set R²: {r2:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyzes the feature importances from GradientBoostingRegressor\n",
    "\n",
    "# Extracts feature importances from the best GradientBoostingRegressor model\n",
    "feature_importances = best_model['model'].feature_importances_\n",
    "\n",
    "# Creates a DataFrame for visualization\n",
    "feature_importances_df = pd.DataFrame({\n",
    "    'Feature': X_encoded.columns,\n",
    "    'Importance': feature_importances\n",
    "}).sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# Displays the top features\n",
    "print(\"Top Features:\")\n",
    "print(feature_importances_df.head(10))\n",
    "\n",
    "# Plots the feature importances\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.barh(feature_importances_df['Feature'], feature_importances_df['Importance'], color='skyblue')\n",
    "plt.gca().invert_yaxis()\n",
    "plt.title(\"Feature Importances from GradientBoostingRegressor\", fontsize=16)\n",
    "plt.xlabel(\"Importance\", fontsize=12)\n",
    "plt.ylabel(\"Feature\", fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Refines the hyperparameter grid for further tuning.\n",
    "# Defines a refined parameter grid for GradientBoostingRegressor\n",
    "refined_param_grid = {\n",
    "    'model__n_estimators': [100, 300, 500],  # Increased number of trees\n",
    "    'model__learning_rate': [0.01, 0.05, 0.1],  # Added smaller learning rates\n",
    "    'model__max_depth': [3, 5, 7],  # Testing a broader range of tree depths\n",
    "    'model__subsample': [0.8, 1.0]  # Added subsampling to prevent overfitting\n",
    "}\n",
    "\n",
    "# Creates a pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('scaler', StandardScaler()),  # Scaling step\n",
    "    ('model', GradientBoostingRegressor(random_state=42))  # Gradient Boosting\n",
    "])\n",
    "\n",
    "# Performs GridSearchCV\n",
    "grid_search_refined = GridSearchCV(pipeline, refined_param_grid, cv=5, scoring='r2', verbose=1)\n",
    "grid_search_refined.fit(X_train, y_train)\n",
    "\n",
    "# Displays the best parameters from refined tuning\n",
    "print(\"Refined Best Parameters:\", grid_search_refined.best_params_)\n",
    "\n",
    "# Evaluates the refined model on the test set\n",
    "refined_best_model = grid_search_refined.best_estimator_\n",
    "y_pred_refined = refined_best_model.predict(X_test)\n",
    "\n",
    "# Calculates the performance metrics for the refined model\n",
    "mae_refined = mean_absolute_error(y_test, y_pred_refined)\n",
    "mse_refined = mean_squared_error(y_test, y_pred_refined)\n",
    "r2_refined = r2_score(y_test, y_pred_refined)\n",
    "\n",
    "print(f\"Refined Test Set MAE: {mae_refined:.2f}\")\n",
    "print(f\"Refined Test Set MSE: {mse_refined:.2f}\")\n",
    "print(f\"Refined Test Set R²: {r2_refined:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
    "Refined Best Parameters: {'model__learning_rate': 0.01, 'model__max_depth': 3, 'model__n_estimators': 500, 'model__subsample': 1.0}\n",
    "Refined Test Set MAE: 2529.26\n",
    "Refined Test Set MSE: 18161303.68\n",
    "Refined Test Set R²: 0.89"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looks at the median absolute error and adjusted R².\n",
    "from sklearn.metrics import median_absolute_error\n",
    "\n",
    "# Median Absolute Error\n",
    "medae = median_absolute_error(y_test, y_pred_refined)\n",
    "print(f\"Median Absolute Error (MedAE): {medae:.2f}\")\n",
    "\n",
    "# Adjusted R²\n",
    "def adjusted_r2(r2, n, p):\n",
    "    \"\"\"Calculate Adjusted R².\"\"\"\n",
    "    return 1 - ((1 - r2) * (n - 1) / (n - p - 1))\n",
    "\n",
    "# Calculates the adjusted R²\n",
    "n = len(y_test)  # Number of observations\n",
    "p = X_test.shape[1]  # Number of features\n",
    "adj_r2 = adjusted_r2(r2_refined, n, p)\n",
    "print(f\"Adjusted R²: {adj_r2:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Results**\n",
    "Median Absolute Error (MedAE): 1659.11\n",
    "Adjusted R²: 0.88"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning: Master Challenge\n",
    "\n",
    "## 8. Calculating Potential Cost or Loss\n",
    "\n",
    "### Challenge:\n",
    "Now that you've built and optimized your models, it's time for the final challenge! Your task is to minimize the Root Mean Squared Error (RMSE) of your model's predictions and calculate the potential financial impact of your model's errors.\n",
    "\n",
    "### Task:\n",
    "1. Calculate the RMSE of your final model's predictions.\n",
    "2. Break down the errors into underestimation and overestimation.\n",
    "3. Calculate the total potential cost or loss to the company.\n",
    "4. Compete with your classmates to see who can achieve the lowest RMSE and financial impact!\n",
    "\n",
    "### Explanation:\n",
    "The RMSE provides an estimate of the average error in your model's predictions. We will also analyze the errors by categorizing them into underestimations and overestimations to understand their financial impact.\n",
    "\n",
    "#### Steps to Calculate Underestimation and Overestimation Errors:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - Use the `mean_squared_error` function from `sklearn.metrics` and pass your actual values (`y_test`) and predicted values (`y_pred_final`) to it.\n",
    "   - Take the square root of the result to get the RMSE.\n",
    "   \n",
    "2. **Calculate Underestimation Error**:\n",
    "   - Identify the instances where the actual charges (`y_test`) are greater than the predicted charges (`y_pred_final`).\n",
    "   - For these instances, calculate the difference between the actual and predicted charges.\n",
    "   - Sum these differences to get the total underestimation error.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - Identify the instances where the actual charges (`y_test`) are less than the predicted charges (`y_pred_final`).\n",
    "   - For these instances, calculate the difference between the predicted and actual charges.\n",
    "   - Sum these differences to get the total overestimation error.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - Add the total underestimation error and the total overestimation error to get the total potential cost or loss.\n",
    "\n",
    "### Let's see who can build the best model!\n",
    "\n",
    "#### Detailed Instructions:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - Use `mean_squared_error` with `y_test` and `y_pred_final`.\n",
    "   - Use `np.sqrt` to take the square root of the result.\n",
    "\n",
    "2. **Calculate Underestimation Error**:\n",
    "   - Use a boolean condition to filter `y_test` values that are greater than `y_pred_final`.\n",
    "   - Subtract the predicted values from the actual values for these instances.\n",
    "   - Sum these differences.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - Use a boolean condition to filter `y_test` values that are less than `y_pred_final`.\n",
    "   - Subtract the actual values from the predicted values for these instances.\n",
    "   - Sum these differences.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - Add the results of the underestimation error and overestimation error to get the total potential cost or loss.\n",
    "\n",
    "### Example Walkthrough:\n",
    "\n",
    "1. **Calculate RMSE**:\n",
    "   - `rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))`\n",
    "   - This gives you the average prediction error in dollars.\n",
    "\n",
    "2. **Calculate Underestimation Error**:\n",
    "   - `underestimation_error = np.sum(y_test[y_test > y_pred_final] - y_pred_final[y_test > y_pred_final])`\n",
    "   - This gives you the total amount by which the model undercharged.\n",
    "\n",
    "3. **Calculate Overestimation Error**:\n",
    "   - `overestimation_error = np.sum(y_pred_final[y_test < y_pred_final] - y_test[y_test < y_pred_final])`\n",
    "   - This gives you the total amount by which the model overcharged.\n",
    "\n",
    "4. **Calculate Total Potential Cost or Loss**:\n",
    "   - `total_potential_loss = underestimation_error + overestimation_error`\n",
    "   - This gives you the total financial impact of the model's errors.\n",
    "\n",
    "### Leaderboard:\n",
    "Post your RMSE score and total potential cost or loss on the class leaderboard. The student with the lowest RMSE and total potential cost or loss wins bragging rights\n",
    "\n",
    "### Post Your Results \n",
    "\n",
    "- Name\n",
    "- Model Type\n",
    "- RMSE\n",
    "- Underestimation Error\n",
    "- Overestimation Error\n",
    "- Total Potential Cost/Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Executes the final challenge, as described above. \n",
    "# Imports the necessary libraries\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'best_model' is the trained model and 'X_test' is the test dataset\n",
    "# Generates predictions from the model\n",
    "y_pred_final = best_model.predict(X_test)\n",
    "\n",
    "# Calculates the RMSE\n",
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred_final))\n",
    "print(f\"Root Mean Squared Error (RMSE): {rmse:.2f}\")\n",
    "\n",
    "# Calculates the underestimation error\n",
    "underestimated_mask = y_test > y_pred_final\n",
    "underestimation_error = np.sum(y_test[underestimated_mask] - y_pred_final[underestimated_mask])\n",
    "print(f\"Total Underestimation Error: {underestimation_error:.2f}\")\n",
    "\n",
    "# Calculates the overestimation error\n",
    "overestimated_mask = y_test < y_pred_final\n",
    "overestimation_error = np.sum(y_pred_final[overestimated_mask] - y_test[overestimated_mask])\n",
    "print(f\"Total Overestimation Error: {overestimation_error:.2f}\")\n",
    "\n",
    "# Calculates the Total Potential Cost or Loss\n",
    "total_potential_loss = underestimation_error + overestimation_error\n",
    "print(f\"Total Potential Cost or Loss: {total_potential_loss:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Submission**\n",
    "\n",
    "Sylvia Y. Perez-Montero\n",
    "\n",
    "**Model Type:** GradientBoostingRegressor\n",
    "\n",
    "**RMSE:** 2360.01\n",
    "\n",
    "**Underestimation error:**  286027.07\n",
    "\n",
    "**Overestimation error:** 346456.28\n",
    "\n",
    "**Total financial impact caused by prediction errors in both directions:** 632483.35"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Congratulations! You've completed the lab. Here's a summary of what we've covered:\n",
    "1. Established a naive baseline using the mean of the target variable.\n",
    "2. Built an initial linear regression model without any feature engineering or optimization.\n",
    "3. Performed feature engineering to create new, potentially useful features.\n",
    "4. Used pipelines and GridSearchCV to optimize the model.\n",
    "5. Evaluated the final model's performance using RMSE to understand its business impact.\n",
    "\n",
    "By following these steps, you now have a robust understanding of how to approach a regression problem, from initial exploration to model optimization and business impact assessment. Great job!\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ae536f6b95df49dd083f07529981141025184c1d22e3e1982b15f49841b31737"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
